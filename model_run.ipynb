{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import networkx as nx\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle as pl\n",
    "import sys\n",
    "\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def figsize(scale):\n",
    "    fig_width_pt = 395.15166                         # Get this from LaTeX using \\the\\textwidth\n",
    "    inches_per_pt = 1.0/72.27                       # Convert pt to inch\n",
    "    golden_mean = (np.sqrt(5.0)-1.0)/2.0            # Aesthetic ratio (you could change this)\n",
    "    fig_width = fig_width_pt*inches_per_pt*scale    # width in inches\n",
    "    fig_height = fig_width*golden_mean              # height in inches\n",
    "    fig_size = [fig_width,fig_height]\n",
    "    return fig_size\n",
    "pgf_with_latex = {                      # setup matplotlib to use latex for output\n",
    "    \"pgf.texsystem\": \"pdflatex\",        # change this if using xetex or lautex\n",
    "    \"text.usetex\": True,                # use LaTeX to write all text\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [],                   # blank entries should cause plots to inherit fonts from the document\n",
    "    \"font.sans-serif\": [],\n",
    "    \"font.monospace\": [],\n",
    "    \"axes.labelsize\": 10,               # LaTeX default is 10pt font.\n",
    "    \"font.size\": 8,\n",
    "    \"legend.fontsize\": 8,               # Make the legend/label fonts a little smaller\n",
    "    \"xtick.labelsize\": 8,\n",
    "    \"ytick.labelsize\": 8,\n",
    "    \"figure.figsize\": figsize(0.9),     # default fig size of 0.9 textwidth\n",
    "    \"pgf.preamble\": [\n",
    "        r\"\\usepackage[utf8x]{inputenc}\",    # use utf8 fonts becasue your computer can handle it :)\n",
    "        r\"\\usepackage[T1]{fontenc}\",        # plots will be generated using this preamble\n",
    "        ]\n",
    "    }\n",
    "matplotlib.rcParams.update(pgf_with_latex)\n",
    "\n",
    "cust_color=[\"#e41a1c\", \"#377eb8\", \"#4daf4a\", \"#984ea3\", \"#ff7f00\", \"#ffff33\", \"#a65628\", \"#f781bf\"]\n",
    "#these colors come from colorbrewer2.org. Each is an RGB triplet\n",
    "dark2_colors = [(0.10588235294117647, 0.6196078431372549, 0.4666666666666667),\n",
    "                (0.8509803921568627, 0.37254901960784315, 0.00784313725490196),\n",
    "                (0.4588235294117647, 0.4392156862745098, 0.7019607843137254),\n",
    "                (0.9058823529411765, 0.1607843137254902, 0.5411764705882353),\n",
    "                (0.4, 0.6509803921568628, 0.11764705882352941),\n",
    "                (0.9019607843137255, 0.6705882352941176, 0.00784313725490196),\n",
    "                (0.6509803921568628, 0.4627450980392157, 0.11372549019607843),\n",
    "                (0.4, 0.4, 0.4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "inline_rc = dict(matplotlib.rcParams) #Sepcific for Matploblib inline Ipython notebook\n",
    "matplotlib.rcParams['savefig.dpi'] = 125\n",
    "matplotlib.rcParams['text.latex.preamble']=[r\"\\usepackage{amsmath,amssymb,amsfonts}\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Different node functions considered in the paper\n",
    "def node_fn(node):\n",
    "    if flag_fn == 1:\n",
    "        temp = int(G.degree(node)>deg_def[0])\n",
    "    elif flag_fn == 2:\n",
    "        temp = int(G.degree(node)<deg_def[1])\n",
    "    elif flag_fn == 3:\n",
    "        temp = G.degree(node)\n",
    "    elif flag_fn == 4:\n",
    "        deg = G.degree(node)\n",
    "        if deg < 2:\n",
    "            temp = 0\n",
    "        else:\n",
    "            temp = 2*nx.triangles(G,node)/(deg*(deg-1))\n",
    "    else:\n",
    "        print(\"Not a defined a function\")\n",
    "        sys.exit(0)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Metropolisâ€“Hastings algorithm\n",
    "def MH_sampling(G,B):\n",
    "    est_MH= []\n",
    "    est_MH_t = 0\n",
    "    sample = np.random.choice(G.nodes())\n",
    "    est_MH_t += node_fn(sample)\n",
    "    est_MH.append(est_MH_t)\n",
    "    for ii in range(2,B+1):\n",
    "        # print \"MH_sample: \",ii\n",
    "        neighbors = nx.neighbors(G,sample)\n",
    "        sample_t = np.random.choice(neighbors)\n",
    "        if np.random.rand() <= (G.degree(sample)/G.degree(sample_t)):\n",
    "            sample = sample_t\n",
    "\n",
    "        est_MH_t += node_fn(sample)\n",
    "        est_MH.append(est_MH_t/ii)\n",
    "    return np.array(est_MH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Respondent-driven sampling\n",
    "def RDS_sampling(G,B):\n",
    "    est_RW = []\n",
    "    est_RW_t1 = 0\n",
    "    est_RW_t2 = 0\n",
    "    sample = np.random.choice(G.nodes())\n",
    "    deg_pr_sent = G.degree(sample)\n",
    "    est_RW_t1 += node_fn(sample)/deg_pr_sent\n",
    "    est_RW_t2 += 1/deg_pr_sent\n",
    "    est_RW.append(est_RW_t1/est_RW_t2)\n",
    "    for ii in range(2,B+1):\n",
    "        # print \"rds_sample: \",ii\n",
    "        neighbors = nx.neighbors(G,sample)\n",
    "        sample = random.choice(neighbors)\n",
    "\n",
    "        deg_pr_sent = G.degree(sample)\n",
    "        est_RW_t1 += node_fn(sample)/deg_pr_sent\n",
    "        est_RW_t2 += 1/deg_pr_sent\n",
    "        est_RW.append(est_RW_t1/est_RW_t2)\n",
    "    return np.array(est_RW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL-MH estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of reinforcement learning based + Metroplis-Hasting sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def RL_estimate_MH(G,super_node,max_B,B_arr,G_no_nodes,techq,tour_N,tour_c):\n",
    "    \"\"\"\n",
    "    1. Returns estimate from tours\n",
    "    2. function  fn: f(D_t) = 1 if D_t > deg_def\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G:            - networkx graph\n",
    "    super_node\t  - node set  for \"super node\"\n",
    "    no_tours\t  - number of tours\n",
    "    \"\"\"\n",
    "    size_super_node = len(super_node)\n",
    "    V = np.zeros((size_super_node,max_B+1))\n",
    "    V_def = np.zeros(max_B)\n",
    "    Z_def = 10\n",
    "    R=[]\n",
    "    xi_arr = []\n",
    "    xi_sum = 0\n",
    "    tour_i = 1\n",
    "    while xi_sum <= max_B:\n",
    "        # print \"RL tour:\", tour_i\n",
    "        R_k = 0\n",
    "        Z_i = random.randint(0,size_super_node-1)\n",
    "        # Z = super_node[Z_i]\n",
    "        # neighbors = nx.neighbors(G,Z)\n",
    "        # sample = random.choice(neighbors)\n",
    "        sample = super_node[Z_i]\n",
    "        neighbors = nx.neighbors(G,sample)\n",
    "        sample_t = np.random.choice(neighbors)\n",
    "        if np.random.rand() <= (G.degree(sample)/G.degree(sample_t)):\n",
    "            sample = sample_t\n",
    "        xi = 1\n",
    "        while sample not in super_node:\n",
    "            R_k += node_fn(sample)\n",
    "            xi += 1\n",
    "            neighbors = nx.neighbors(G,sample)\n",
    "            sample_t = random.choice(neighbors)\n",
    "            if np.random.rand() <= (G.degree(sample)/G.degree(sample_t)):\n",
    "                sample = sample_t\n",
    "        R_k += node_fn(sample)\n",
    "        R.append(R_k)\n",
    "        xi_sum += xi\n",
    "        # xi_arr maintains the renewal epochs \\xi(1), \\xi(1)+\\xi(2), ....\n",
    "        xi_arr.append(xi_sum)\n",
    "\n",
    "        V[:,tour_i] = V[:,(tour_i-1)]\n",
    "\n",
    "        Z_f = super_node.index(sample)\n",
    "        if techq == 1:\n",
    "            V_def[tour_i-1] = V[Z_def,tour_i-1]\n",
    "            V[Z_i][tour_i] += (1 / (np.ceil(tour_i/tour_N)+tour_c))* \\\n",
    "                            (R_k - V_def[tour_i-1]*xi + V[Z_f][tour_i-1] - V[Z_i][tour_i-1])\n",
    "        elif techq == 2:\n",
    "            V_def[tour_i-1] = np.average(V[:,tour_i-1])\n",
    "            V[Z_i][tour_i] += (1 / (np.ceil(tour_i/tour_N)+tour_c))* \\\n",
    "                            (R_k - V_def[tour_i-1]*xi + V[Z_f][tour_i-1] - V[Z_i][tour_i-1])\n",
    "        elif techq == 3:\n",
    "            V_def[tour_i-1] = np.min(V[:,tour_i-1])\n",
    "            V[Z_i][tour_i] += (1 / (np.ceil(tour_i/tour_N)+tour_c))* \\\n",
    "                            (R_k - V_def[tour_i-1]*xi + V[Z_f][tour_i-1] - V[Z_i][tour_i-1])\n",
    "        else:\n",
    "            print(\"Wrong value for RL technique\")\n",
    "            sys.exit(0)\n",
    "        tour_i += 1\n",
    "    # return(V_def[1:tour_i-1])\n",
    "    xi_arrr = np.array(xi_arr)\n",
    "    ind = np.zeros(len(B_arr),dtype = int)\n",
    "    for ii,i in enumerate(B_arr):\n",
    "        ind[ii]=np.argmax(xi_arrr > i)-1\n",
    "    return (V_def[ind+1])\n",
    "    # return (V_def[1:tour_i-1], np.array(R)[:tour_i-1], np.array(xi_arr)[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL-RW with Lazy Random Walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of reinforcement learning based + lazy random walk sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def RL_LRW_estimate(G,super_node,max_B,B_arr,G_no_nodes,techq,tour_N,tour_c):\n",
    "    \"\"\"\n",
    "    1. Returns estimate from tours\n",
    "    2. function  fn: f(D_t) = 1 if D_t > deg_def\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G:            - networkx graph\n",
    "    super_node\t  - node set  for \"super node\"\n",
    "    no_tours\t  - number of tours\n",
    "    \"\"\"\n",
    "    size_super_node = len(super_node)\n",
    "    V = np.zeros((size_super_node,max_B+1))\n",
    "    V_def = np.zeros(max_B)\n",
    "    Z_def = 10\n",
    "    R=[]\n",
    "    xi_arr = []\n",
    "    xi_sum = 0\n",
    "    tour_i = 1\n",
    "    \n",
    "    while xi_sum <= max_B:\n",
    "\n",
    "        R_k = 0\n",
    "        Z_i = random.randint(0,size_super_node-1)\n",
    "        sample = super_node[Z_i]\n",
    "        \n",
    "        # sample_t contains the previous sample\n",
    "        sample_t =  sample\n",
    "        if not np.random.randint(2,size = 1):\n",
    "            neighbors = nx.neighbors(G,sample)\n",
    "            sample = np.random.choice(neighbors)\n",
    "\n",
    "        xi = 1\n",
    "        LH = 1\n",
    "        while sample not in super_node:\n",
    "            R_k += node_fn(sample)\n",
    "            \n",
    "            if sample == sample_t:\n",
    "                LH_1 = 1-sum([1/max(G.degree(sample_t), G.degree(sample_t_n))\\\n",
    "                              for sample_t_n in neighbors])\n",
    "                LH_2 = 1/2\n",
    "            else:\n",
    "                LH_1 = 1/max(G.degree(sample_t), G.degree(sample))\n",
    "                LH_2 = 1/(2*G.degree(sample_t))\n",
    "                \n",
    "            LH *= LH_1 / LH_2\n",
    "            \n",
    "            sample_t = sample\n",
    "            if not np.random.randint(2,size = 1):\n",
    "                neighbors = nx.neighbors(G,sample)\n",
    "                sample = np.random.choice(neighbors)\n",
    "            xi += 1\n",
    "            \n",
    "        R_k += node_fn(sample)\n",
    "        R.append(R_k)\n",
    "        xi_sum += xi\n",
    "        xi_arr.append(xi_sum)\n",
    "        \n",
    "        LH_1 = 1/max(G.degree(sample), G.degree(sample_t))\n",
    "        LH_2 = 1/(2*G.degree(sample_t))\n",
    "        LH *= LH_1 / LH_2\n",
    "        \n",
    "        V[:,tour_i] = V[:,(tour_i-1)]\n",
    "\n",
    "        Z_f = super_node.index(sample)\n",
    "        if techq == 1:\n",
    "            V_def[tour_i-1] = V[Z_def,tour_i-1]\n",
    "            V[Z_i][tour_i] += LH * (1 / (np.ceil(tour_i/tour_N)+tour_c)) \\\n",
    "                                * (R_k - V_def[tour_i-1]*xi + V[Z_f][tour_i-1] - V[Z_i][tour_i-1])\n",
    "        elif techq == 2:\n",
    "            V_def[tour_i-1] = np.average(V[:,tour_i-1])\n",
    "            V[Z_i][tour_i] +=  LH * (1 / (np.ceil(tour_i/tour_N)+tour_c)) \\\n",
    "                                * (R_k - V_def[tour_i-1]*xi + V[Z_f][tour_i-1] - V[Z_i][tour_i-1])\n",
    "        elif techq == 3:\n",
    "            V_def[tour_i-1] = np.min(V[:,tour_i-1])\n",
    "            V[Z_i][tour_i] += LH * (1 / (np.ceil(tour_i/tour_N)+tour_c)) \\\n",
    "                                * (R_k - V_def[tour_i-1]*xi + V[Z_f][tour_i-1] - V[Z_i][tour_i-1])\n",
    "        else:\n",
    "            print(\"Wrong value for RL technique\")\n",
    "            sys.exit(0)\n",
    "        tour_i += 1\n",
    "\n",
    "    xi_arrr = np.array(xi_arr)\n",
    "    ind = np.zeros(len(B_arr),dtype = int)\n",
    "    for ii,i in enumerate(B_arr):\n",
    "        ind[ii]=np.argmax(xi_arrr > i)-1\n",
    "    return (V_def[ind+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL-RW with SRW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of reinforcement learning based + standard random walk sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def RL_SRW_estimate(G,super_node,max_B,B_arr,G_no_nodes,techq,tour_N,tour_c):\n",
    "    \"\"\"\n",
    "    1. Returns estimate from tours\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G:            - networkx graph\n",
    "    super_node\t  - node set  for \"super node\"\n",
    "    no_tours\t  - number of tours\n",
    "    To be completed\n",
    "    \"\"\"\n",
    "    size_super_node = len(super_node)\n",
    "    V = np.zeros((size_super_node,max_B+1))\n",
    "    V_def = np.zeros(max_B)\n",
    "    Z_def = 10\n",
    "    R=[]\n",
    "    xi_arr = []\n",
    "    xi_sum = 0\n",
    "    tour_i = 1\n",
    "    while xi_sum <= max_B:\n",
    "\n",
    "        R_k = 0\n",
    "        Z_i = random.randint(0,size_super_node-1)\n",
    "        sample = super_node[Z_i]\n",
    "        \n",
    "        # sample_t contains the previous sample\n",
    "        sample_t =  sample\n",
    "        neighbors = nx.neighbors(G,sample)\n",
    "        sample = np.random.choice(neighbors)\n",
    "\n",
    "        xi = 1\n",
    "        LH = 1\n",
    "        while sample not in super_node:\n",
    "            R_k += node_fn(sample)\n",
    "            \n",
    "            LH_1 = 1/max(G.degree(sample_t), G.degree(sample))\n",
    "            LH_2 = 1/(G.degree(sample_t))\n",
    "            LH *= LH_1 / LH_2\n",
    "            \n",
    "            sample_t = sample\n",
    "            neighbors = nx.neighbors(G,sample)\n",
    "            sample = np.random.choice(neighbors)\n",
    "            xi += 1\n",
    "            \n",
    "        R_k += node_fn(sample)\n",
    "        R.append(R_k)\n",
    "        xi_sum += xi\n",
    "        xi_arr.append(xi_sum)\n",
    "        \n",
    "        LH_1 = 1/max(G.degree(sample), G.degree(sample_t))\n",
    "        LH_2 = 1/(G.degree(sample_t))\n",
    "        LH *= LH_1 / LH_2\n",
    "              \n",
    "        V[:,tour_i] = V[:,(tour_i-1)]\n",
    "\n",
    "        Z_f = super_node.index(sample)\n",
    "        if techq == 1:\n",
    "            V_def[tour_i-1] = V[Z_def,tour_i-1]\n",
    "            V[Z_i][tour_i] += LH * (1 / (np.ceil(tour_i/tour_N)+tour_c)) \\\n",
    "                                * (R_k - V_def[tour_i-1]*xi + V[Z_f][tour_i-1] - V[Z_i][tour_i-1])\n",
    "        elif techq == 2:\n",
    "            V_def[tour_i-1] = np.average(V[:,tour_i-1])\n",
    "            V[Z_i][tour_i] +=  LH * (1 / (np.ceil(tour_i/tour_N)+tour_c)) \\\n",
    "                                * (R_k - V_def[tour_i-1]*xi + V[Z_f][tour_i-1] - V[Z_i][tour_i-1])\n",
    "        elif techq == 3:\n",
    "            V_def[tour_i-1] = np.min(V[:,tour_i-1])\n",
    "            V[Z_i][tour_i] += LH * (1 / (np.ceil(tour_i/tour_N)+tour_c)) \\\n",
    "                                * (R_k - V_def[tour_i-1]*xi + V[Z_f][tour_i-1] - V[Z_i][tour_i-1])\n",
    "        else:\n",
    "            print(\"Wrong value for RL technique\")\n",
    "            sys.exit(0)\n",
    "        tour_i += 1\n",
    "        \n",
    "    xi_arrr = np.array(xi_arr)\n",
    "    ind = np.zeros(len(B_arr),dtype = int)\n",
    "    for ii,i in enumerate(B_arr):\n",
    "        ind[ii]=np.argmax(xi_arrr > i)-1\n",
    "    return V_def[ind+1]\n",
    "    # return (V_def[1:tour_i-1], np.array(R)[:tour_i-1], np.array(xi_arr)[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RT-estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratio with tours estimator (RT-estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def random_walk_tour_estimate(G,super_node,nbr_out_sup,F_org_sup_1,vol_sup_node,max_B,B_arr):\n",
    "    \"\"\"\n",
    "    1. Returns estimate from tours\n",
    "    2. function  fn: f(D_t) = 1 if D_t > deg_def\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G:            - networkx graph\n",
    "    super_node\t  - node set  for \"super node\"\n",
    "    no_tours\t  - number of tours\n",
    "    \"\"\"\n",
    "\n",
    "    R = []\n",
    "    R_1 =[]\n",
    "    R_2 = []\n",
    "    summ = 0\n",
    "    summ1 =0\n",
    "    summ2 =0\n",
    "    \n",
    "    xi_arr = []\n",
    "    xi_sum = 0\n",
    "\n",
    "    size_super_node = len(super_node)\n",
    "    tour_i = 1\n",
    "    while xi_sum <= max_B:\n",
    "\n",
    "        R_k1 = 0\n",
    "        R_k2 = 0\n",
    "        \n",
    "        sample = random.choice(nbr_out_sup)\n",
    "        xi = 1\n",
    "        while sample not in super_node:\n",
    "            deg_sample = G.degree(sample)\n",
    "            R_k1 += node_fn(sample)/deg_sample\n",
    "            R_k2 += 1/deg_sample\n",
    "            xi += 1\n",
    "            neighbors = nx.neighbors(G,sample)\n",
    "            sample = random.choice(neighbors)\n",
    "\n",
    "        R_k1 += F_org_sup_1/vol_sup_node\n",
    "        R_k2 += size_super_node/vol_sup_node\n",
    "        \n",
    "        R_1.append(R_k1+summ1)\n",
    "        R_2.append(R_k2+summ2)\n",
    "        \n",
    "        summ1 += R_k1\n",
    "        summ2 += R_k2\n",
    "        \n",
    "        xi_sum += xi\n",
    "        xi_arr.append(xi_sum)\n",
    "        tour_i += 1\n",
    "        \n",
    "    R_1 = np.array(R_1)\n",
    "    R_2 = np.array(R_2)\n",
    "    R = R_1/R_2\n",
    "        \n",
    "    xi_arrr = np.array(xi_arr)\n",
    "    ind = np.zeros(len(B_arr),dtype = int)\n",
    "    for ii,it in enumerate(B_arr):\n",
    "        ind[ii]=np.argmax(xi_arrr > it)-1 \n",
    "        # Without -1, argmax chooses the xi_arrth element which crosses \"it\"\n",
    "        # With -1, we go one step backwards\n",
    "    return (R[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_i = 1 # 1 for Friendster, 2 for Les miserables network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "if G_i == 1:\n",
    "    tour_N = 25 #5\n",
    "    tour_c = 0\n",
    "    deg_def = [50]\n",
    "    flag_fn = 1 # 1 for g(v) = d(v) > 25, 4 for avg clustering coeff\n",
    "if G_i == 2:\n",
    "    tour_N =  10 #5\n",
    "    tour_c = 0\n",
    "    deg_def = [10,4]\n",
    "    flag_fn = 1 # 1 for g(v) = d(v) > 10, 2 for g(v) = d(v) < 4, 3 for avg degree, 4 for avg clustering coeff\n",
    "    asy_var_MH_lesmis = [4.4154,14.93508,1.204e+03]\n",
    "    asy_var_RDS_lesmis = [1.1084,3.3240,272.7649]\n",
    "\n",
    "max_B = 10000 # maximum budget\n",
    "no_runs = 100 # no. of runs to average\n",
    "run_MH = 0 # Flag for doing MH simulation\n",
    "run_RDS = 1 # Flag for doing RDS simulation\n",
    "run_RL_MH = 1 # Flag for doing RL simulation with MH sampling\n",
    "run_RL_RW = 1 # Flag for doing RL simulation with RWRDS (actually unbiased) sampling\n",
    "\n",
    "SHOW_VAR_CONVG = 0\n",
    "ABS_ERROR = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "if G_i == 1:\n",
    "    G = nx.read_edgelist(\"friendster_community1_trimmed.edgelist\",nodetype = int)\n",
    "elif G_i == 2:\n",
    "    G = nx.read_edgelist(\"lesmis.edgelist\", nodetype = int)\n",
    "G_no_edges=G.number_of_edges()\n",
    "G_no_nodes=G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "if G_i == 1:\n",
    "    if flag_fn == 1:\n",
    "        F_org = 0.265712074303 #sum([1 for i in G.nodes() if G.degree(i) ])/G_no_nodes\n",
    "    elif flag_fn == 4:\n",
    "        F_org = 0.4491010966748313\n",
    "    else:\n",
    "        sys.exit(\"Invalid function\")\n",
    "        \n",
    "elif G_i == 2:\n",
    "    if (flag_fn == 1) or (flag_fn == 2):\n",
    "        F_org = sum([node_fn(i) for i in G.nodes()])/G_no_nodes\n",
    "    elif flag_fn == 3:\n",
    "        F_org = 2*G_no_edges/G_no_nodes\n",
    "    elif flag_fn == 4:\n",
    "        F_org = nx.average_clustering(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "if run_MH:\n",
    "    MSE_MH_t = 0\n",
    "    for ii in range(1,no_runs+1):\n",
    "        print(\"MHruns: \",ii)\n",
    "        MSE_MH_t += (MH_sampling(G,max_B)-F_org)**2\n",
    "    MSE_MH = MSE_MH_t/(no_runs)\n",
    "\n",
    "    if SHOW_VAR_CONVG == 1:\n",
    "        MSE_MH = MSE_MH*np.arange(1,max_B+1)\n",
    "    else:\n",
    "        MSE_MH = np.sqrt(MSE_MH)/F_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "if run_RDS:\n",
    "    MSE_rds_t = 0\n",
    "    for ii in range(1,no_runs+1):\n",
    "        print(\"RDSruns: \",ii)\n",
    "        MSE_rds_t += (RDS_sampling(G,max_B)-F_org)**2\n",
    "    MSE_rds = MSE_rds_t/(no_runs)\n",
    "\n",
    "    if SHOW_VAR_CONVG == 1:\n",
    "        MSE_rds = MSE_rds*np.arange(1,max_B+1)\n",
    "    else:\n",
    "        MSE_rds = np.sqrt(MSE_rds)/F_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "if run_RL_MH:\n",
    "    ## Super-node calculations =================================================\n",
    "    size_super_node = int(input(\"Size of super node (def = 1000): \") or \"1000\")\n",
    "    if size_super_node == 1:\n",
    "        sup_node_1_sel = input(\"Select highest degree node (y/n), def = y): \") or \"y\"\n",
    "        if sup_node_1_sel is 'y':\n",
    "            super_node = [max(G.degree(), key=G.degree().get)]\n",
    "            print(\"Selected the node with highest degree !!\")\n",
    "        else:\n",
    "            super_node = random.sample(G.nodes(), size_super_node) #super-node formation from uniform samples\n",
    "    if size_super_node is not 1:\n",
    "        super_node = random.sample(G.nodes(), size_super_node) #super-node formation from uniform samples\n",
    "        print(\"Size of super node is not 1\")\n",
    "    ## =========================================================================\n",
    "    B_arr = np.arange(100,max_B+1,100)\n",
    "\n",
    "    for ii in range(1,no_runs+1):\n",
    "        print(\"RLruns: \",ii)\n",
    "        temp = RL_estimate_MH(G,super_node,max_B,B_arr,G_no_nodes, 2,tour_N,tour_c)\n",
    "        MSE_RL_t = (temp-F_org)**2\n",
    "        if ii == 1:\n",
    "            MSE_RL = MSE_RL_t\n",
    "        else:\n",
    "            MSE_RL = ((ii-1)/ii)*MSE_RL + MSE_RL_t/ii\n",
    "\n",
    "    if SHOW_VAR_CONVG == 1:\n",
    "        MSE_RL = MSE_RL*B_arr\n",
    "    else:\n",
    "        MSE_RL = np.sqrt(MSE_RL)/F_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"MSE_RL\", MSE_RL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL-RW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "if run_RL_RW:\n",
    "    ## Super-node calculations =================================================\n",
    "    size_super_node = int(input(\"Size of super node (def = 1000): \") or \"1000\")\n",
    "    if size_super_node == 1:\n",
    "        sup_node_1_sel = input(\"Select highest degree node (y/n), def = y): \") or \"y\"\n",
    "        if sup_node_1_sel is 'y':\n",
    "            super_node = [max(G.degree(), key=G.degree().get)]\n",
    "            print(\"Selected the node with highest degree !!\")\n",
    "        else:\n",
    "            super_node = random.sample(G.nodes(), size_super_node) #super-node formation from uniform samples\n",
    "    if size_super_node is not 1:\n",
    "        super_node = random.sample(G.nodes(), size_super_node) #super-node formation from uniform samples\n",
    "        print(\"Size of super node is not 1\")\n",
    "    ## =========================================================================\n",
    "    B_arr = np.arange(100,max_B+1,100)\n",
    "\n",
    "    for ii in range(1,no_runs+1):\n",
    "        print(\"RLruns: \",ii)\n",
    "#         temp = RL_estimate_RW(G,super_node,max_B,B_arr,G_no_nodes, 2,tour_N,tour_c)\n",
    "        temp = RL_LRW_estimate(G = G,super_node = super_node, max_B = max_B ,B_arr = B_arr ,\n",
    "                                  G_no_nodes = G_no_nodes ,techq = 2,tour_N = tour_N ,tour_c = tour_c)\n",
    "        MSE_RL_RW_t = (temp-F_org)**2\n",
    "        if ii == 1:\n",
    "            MSE_RL_RW = MSE_RL_RW_t\n",
    "        else:\n",
    "            MSE_RL_RW = ((ii-1)/ii)*MSE_RL_RW + MSE_RL_RW_t/ii\n",
    "\n",
    "    if SHOW_VAR_CONVG == 1:\n",
    "        MSE_RL_RW = MSE_RL_RW*B_arr\n",
    "    else:\n",
    "        MSE_RL_RW = np.sqrt(MSE_RL_RW)/F_org "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "MSE_RL_RW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratio estimator comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## Super-node calculations =================================================\n",
    "size_super_node = int(input(\"Size of super node (def = 1000): \") or \"1000\")\n",
    "if size_super_node == 1:\n",
    "    sup_node_1_sel = input(\"Select highest degree node (y/n), def = y): \") or \"y\"\n",
    "    if sup_node_1_sel is 'y':\n",
    "        super_node = [max(G.degree(), key=G.degree().get)]\n",
    "        print(\"Selected the node with highest degree !!\")\n",
    "    else:\n",
    "        super_node = random.sample(G.nodes(), size_super_node) #super-node formation from uniform samples\n",
    "if size_super_node is not 1:\n",
    "    super_node = random.sample(G.nodes(), size_super_node) #super-node formation from uniform samples\n",
    "    print (\"Size of super node is not 1\")\n",
    "## =========================================================================\n",
    "#Finding super_node's neighbours outside super node\n",
    "nbr_out_sup=[]\n",
    "sum_temp=0\n",
    "F_org_sup_1=0\n",
    "i=0\n",
    "for node_s in super_node:\n",
    "    print(\"super node \", i)\n",
    "    i+=1\n",
    "    list_s_n=[node_s_n for node_s_n in nx.neighbors(G,node_s) if node_s_n not in super_node]\n",
    "    nbr_out_sup=nbr_out_sup+list_s_n\n",
    "    F_org_sup_1 += node_fn(node_s)\n",
    "\n",
    "vol_sup_node = len(nbr_out_sup)\n",
    "## =========================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "B_arr = np.arange(100,max_B+1,100)\n",
    "MSE_RL_MH_t = 0\n",
    "MSE_RL_RW_t = 0\n",
    "MSE_tour_ratio_t = 0\n",
    "MSE_rds_t = 0\n",
    "\n",
    "for ii in range(1,no_runs+1):\n",
    "    print(\"runs: \",ii)\n",
    "    temp_tour_ratio = random_walk_tour_estimate(G,super_node,nbr_out_sup,F_org_sup_1,vol_sup_node,max_B,B_arr)\n",
    "    \n",
    "    MSE_tour_ratio_t = (temp_tour_ratio-F_org)**2\n",
    "    MSE_rds_t += (RDS_sampling(G,max_B)-F_org)**2\n",
    "\n",
    "    if ii == 1:\n",
    "        MSE_tour_ratio = MSE_tour_ratio_t\n",
    "    else:\n",
    "        MSE_tour_ratio = ((ii-1)/ii)*MSE_tour_ratio + MSE_tour_ratio_t/ii\n",
    "MSE_rds = MSE_rds_t/(no_runs)\n",
    "        \n",
    "# if SHOW_VAR_CONVG == 1:\n",
    "#     MSE_RL_RW = MSE_RL_RW*B_arr\n",
    "# else:\n",
    "#     MSE_RL_RW = np.sqrt(MSE_RL_RW)/F_org "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import brewer2mpl\n",
    "\n",
    "# Get \"Set2\" colors from ColorBrewer (all colorbrewer scales: http://bl.ocks.org/mbostock/5577023)\n",
    "set2 = brewer2mpl.get_map('Set2', 'qualitative', 8).mpl_colors\n",
    "# plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "FIGSIZE_REQD = 1\n",
    "fig, ax = plt.subplots(FIGSIZE_REQD)\n",
    "\n",
    "ax=plt.axes(frameon=1)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# Real plotting goes here:\n",
    "\n",
    "if SHOW_VAR_CONVG == 1:\n",
    "    plt.plot(np.arange(11,max_B+1),MSE_MH[10:], color=cust_color[1], \\\n",
    "     linewidth=1,linestyle='-',label='MH-MCMC')\n",
    "    if (G_i == 2):\n",
    "        plt.axhline(asy_var_MH_lesmis[flag_fn-1], xmin=0, color=cust_color[1],alpha=0.5, \\\n",
    "        linewidth=1.35, linestyle=\"--\", label = 'Asymp. variance of MH-MCMC') #Plot asymptotic variance\n",
    "    \n",
    "    plt.plot(range(11,max_B+1),MSE_rds[10:], color=cust_color[6], \\\n",
    "     linewidth=1,linestyle='-',label='RDS')\n",
    "    if (G_i == 2):\n",
    "        plt.axhline(asy_var_RDS_lesmis[flag_fn-1], xmin=0, color=cust_color[6],alpha=0.5, \\\n",
    "        linewidth=1.35, linestyle=\":\", label = 'Asymp. variance of RDS') #Plot asymptotic variance\n",
    "\n",
    "    plt.plot(B_arr[1:],MSE_RL[1:], color=cust_color[3], \\\n",
    "     linewidth=1,linestyle='-',label='RL technique')\n",
    "\n",
    "else:\n",
    "#     plt.plot(np.arange(11,max_B+1),MSE_MH[10:], color=cust_color[1], \\\n",
    "#      linewidth=1,linestyle='-',label='MH-MCMC')      \n",
    "\n",
    "#     plt.plot(range(11,max_B+1),MSE_rds[10:], color=cust_color[6], \\\n",
    "#      linewidth=1,linestyle='-',label='RDS')\n",
    "\n",
    "#     plt.plot(B_arr,MSE_RL, color=cust_color[3], \\\n",
    "#      linewidth=1,linestyle='-',label='RL technique MH')\n",
    "        plt.plot(B_arr,MSE_tour_ratio_fr_average_clust_coeff_sup_1000_save, color= cust_color[1], \\\n",
    "        linewidth=1,linestyle='-',label='Tour technique')\n",
    "#         plt.plot(B_arr,MSE_RL_MH, color=cust_color[4], \\\n",
    "#         linewidth=1,linestyle='-',label='RL MH')\n",
    "#         plt.plot(B_arr,MSE_RL_RW, color=cust_color[5], \\\n",
    "#         linewidth=1,linestyle='-',label='RL RW')\n",
    "        plt.plot(range(11,max_B+1),MSE_rds_fr_avg_clust_coeff_save[10:], color= cust_color[6], \\\n",
    "         linewidth=1,linestyle='-',label='RDS')\n",
    "\n",
    "    \n",
    "#     plt.plot(B_arr,MSE_RL_RW, color=cust_color[4], \\\n",
    "#      linewidth=1,linestyle='-',label='RL technique RW')\n",
    "\n",
    "\n",
    "# =======================\n",
    "\n",
    "ax.set_xlabel('Budget $B$')\n",
    "if SHOW_VAR_CONVG == 1:\n",
    "    ylabel_txt = r'$\\mbox{MSE}\\times B$'\n",
    "else:\n",
    "    ylabel_txt = 'NRMSE'\n",
    "\n",
    "ax.set_ylabel(ylabel_txt) #USE labelpad = -1 to move label to axis\n",
    "\n",
    "legend=ax.legend(fancybox = True, framealpha=0.5,loc='best')\n",
    "\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.9')\n",
    "frame.set_edgecolor('0.75')\n",
    "plt.grid(alpha = 0.7)\n",
    "\n",
    "# props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "# textstr = \"Super node size =%d\"%(size_super_node)\n",
    "# ax.text(0.02, 0.95,textstr, transform=ax.transAxes, fontsize= 8,\\\n",
    "#         verticalalignment='top', bbox=props)\n",
    "\n",
    "### QUICK INSET SETTINGS ####\n",
    "ax2 = plt.axes([.6, .3, .3, .3]) #[left bottom width height]\n",
    "plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "plt.grid(alpha = 0.7)\n",
    "\n",
    "plt.plot(B_arr,MSE_tour_ratio_fr_average_clust_coeff_sup_1000_save, color=cust_color[1], \\\n",
    "linewidth=1,linestyle='-')\n",
    "plt.plot(range(11,max_B+1),MSE_rds_fr_avg_clust_coeff_save[10:], color=cust_color[6], \\\n",
    " linewidth=1,linestyle='-',label='RDS')\n",
    "ax2.set_xlim(left = 2000)\n",
    "ax2.set_ylim(top = 0.001)\n",
    "\n",
    "plt.locator_params(axis='y',nbins=4)#to specify number of ticks on both or any single axes\n",
    "plt.locator_params(axis='x',nbins=8)\n",
    "try:\n",
    "    legend=ax2.legend(fancybox = True, framealpha=0.5,loc='best')\n",
    "    frame = legend.get_frame()\n",
    "    frame.set_facecolor('0.9')\n",
    "    frame.set_edgecolor('0.7')\n",
    "except:\n",
    "    pass\n",
    "### -------------------- ####\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "textstr = r'Friendster graph: \\\\Estimate avg.\\ clustering coefficient'\n",
    "# textstr = r'Friendster graph:\\\\ Estimate $\\displaystyle \\frac{1}{\\lvert V\\rvert} \\sum_{u \\in V}\\mathbb{I}\\{d(u) > 50\\}$'\n",
    "# textstr = r'Les Miserables graph: Estimate $\\displaystyle \\frac{1}{\\lvert V\\rvert} \\sum_{u \\in V} d(u)$'\n",
    "# textstr = r'Les Miserables graph: Estimate avg.\\ clustering coefficient'\n",
    "\n",
    "\n",
    "plt.text(0.05, 0.7,textstr,transform=ax.transAxes, bbox=props)\n",
    "\n",
    "if SHOW_VAR_CONVG == 1:\n",
    "    plt.savefig('plot_estn_comp_csonet_var.pdf',bbox_inches='tight',pad_inches = 0.05)\n",
    "    pl.dump(ax,file('plot_estn_comp_csonet_var.pickle','w'))\n",
    "    print(\"Saved the file plot_estn_comp_csonet_var\")\n",
    "else:\n",
    "    plt.savefig('plot_estn_comp_csonet_mse.pdf',bbox_inches='tight',pad_inches = 0.05)\n",
    "    pl.dump(ax2,open('plot_estn_comp_csonet_mse.pickle','wb'))\n",
    "    pickle.dump(fig, open('myplot.pickle', 'wb')) #ax corresponds to fig, ax = plt.subplots()\n",
    "\n",
    "    print(\"Saved the file plot_estn_comp_csonet_mse\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
